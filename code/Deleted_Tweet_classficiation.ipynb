{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "manufactured-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaning-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liberal-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('pronoun_covid_jan_apr_2020_deleted_check_1.csv')\n",
    "df2=pd.read_csv('pronoun_covid_jan_apr_2020_deleted_check_2.csv')\n",
    "#df3.to_csv('pronoun_covid_jan_apr_2020_deleted_check_3.csv')\n",
    "#df4.to_csv('pronoun_covid_jan_apr_2020_deleted_check_4.csv')\n",
    "#df5.to_csv('pronoun_covid_jan_apr_2020_deleted_check_5.csv')\n",
    "#df6.to_csv('pronoun_covid_jan_apr_2020_deleted_check_6.csv')\n",
    "##df7.to_csv('pronoun_covid_jan_apr_2020_deleted_check_7.csv')\n",
    "#df8.to_csv('pronoun_covid_jan_apr_2020_deleted_check_8.csv')\n",
    "#df9.to_csv('pronoun_covid_jan_apr_2020_deleted_check_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "resistant-charity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Created At (UTC)</th>\n",
       "      <th>Retweet count</th>\n",
       "      <th>Coordinates latitude</th>\n",
       "      <th>Coordinates longitude</th>\n",
       "      <th>Favorite count</th>\n",
       "      <th>Places ID</th>\n",
       "      <th>Places Name</th>\n",
       "      <th>Source</th>\n",
       "      <th>...</th>\n",
       "      <th>Original tweet author location (if comment)</th>\n",
       "      <th>Original tweet author followers count (if comment)</th>\n",
       "      <th>Original tweet author verified (if comment)</th>\n",
       "      <th>Original tweet author description (if comment)</th>\n",
       "      <th>Original tweet author statuses count (if comment)</th>\n",
       "      <th>Original tweet author friends count (if comment)</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>pronoun_len</th>\n",
       "      <th>TrueFalse</th>\n",
       "      <th>nondeleted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245138816643579906</td>\n",
       "      <td>rt @dawnbutlerbrent: another nhs frontline wor...</td>\n",
       "      <td>2020-04-01 00:00:02</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['He', 'He']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.245139e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245138837476605952</td>\n",
       "      <td>rt @ncdcgov: we've updated national case defin...</td>\n",
       "      <td>2020-04-01 00:00:07</td>\n",
       "      <td>2800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['We']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245138846674812928</td>\n",
       "      <td>rt @brithume: nationwide fever-tracking data i...</td>\n",
       "      <td>2020-04-01 00:00:09</td>\n",
       "      <td>394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['they']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223395606854389761</td>\n",
       "      <td>today things getting worse,my father had a hig...</td>\n",
       "      <td>2020-02-01 00:00:16</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['we', 'He', 'I', 'him']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245138869814779905</td>\n",
       "      <td>@ingrahamangle a friend of mine has covid19 an...</td>\n",
       "      <td>2020-04-01 00:00:14</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['him', 'they', 'him']</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               Text  \\\n",
       "0  1245138816643579906  rt @dawnbutlerbrent: another nhs frontline wor...   \n",
       "1  1245138837476605952  rt @ncdcgov: we've updated national case defin...   \n",
       "2  1245138846674812928  rt @brithume: nationwide fever-tracking data i...   \n",
       "3  1223395606854389761  today things getting worse,my father had a hig...   \n",
       "4  1245138869814779905  @ingrahamangle a friend of mine has covid19 an...   \n",
       "\n",
       "      Created At (UTC)  Retweet count  Coordinates latitude  \\\n",
       "0  2020-04-01 00:00:02           1800                   NaN   \n",
       "1  2020-04-01 00:00:07           2800                   NaN   \n",
       "2  2020-04-01 00:00:09            394                   NaN   \n",
       "3  2020-02-01 00:00:16            162                   NaN   \n",
       "4  2020-04-01 00:00:14              1                   NaN   \n",
       "\n",
       "   Coordinates longitude  Favorite count Places ID Places Name  \\\n",
       "0                    NaN               0       NaN         NaN   \n",
       "1                    NaN               0       NaN         NaN   \n",
       "2                    NaN               0       NaN         NaN   \n",
       "3                    NaN             363       NaN         NaN   \n",
       "4                    NaN               1       NaN         NaN   \n",
       "\n",
       "                                              Source  ...  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...  ...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...  ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...  ...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...  ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...  ...   \n",
       "\n",
       "   Original tweet author location (if comment)  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  Original tweet author followers count (if comment)  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "  Original tweet author verified (if comment)  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "  Original tweet author description (if comment)  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "\n",
       "  Original tweet author statuses count (if comment)  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "   Original tweet author friends count (if comment)                   pronoun  \\\n",
       "0                                               NaN              ['He', 'He']   \n",
       "1                                               NaN                    ['We']   \n",
       "2                                               NaN                  ['they']   \n",
       "3                                               NaN  ['we', 'He', 'I', 'him']   \n",
       "4                                               NaN    ['him', 'they', 'him']   \n",
       "\n",
       "  pronoun_len  TrueFalse  nondeleted_id  \n",
       "0           2          1   1.245139e+18  \n",
       "1           1          1            NaN  \n",
       "2           1          1            NaN  \n",
       "3           4          1            NaN  \n",
       "4           3          1            NaN  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_del=df1[df1.nondeleted_id.isnull()]\n",
    "df1_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df2_del=df2[df2.nondeleted_id.isnull()]\n",
    "df2_nondel=df2[df2.nondeleted_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "super-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3_del=df1[df1.nondeleted_id.isnull()]\n",
    "df3_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df4_del=df1[df1.nondeleted_id.isnull()]\n",
    "df4_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df5_del=df1[df1.nondeleted_id.isnull()]\n",
    "df5_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df6_del=df1[df1.nondeleted_id.isnull()]\n",
    "df6_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df7_del=df1[df1.nondeleted_id.isnull()]\n",
    "df7_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df8_del=df1[df1.nondeleted_id.isnull()]\n",
    "df8_nondel=df1[df1.nondeleted_id.notnull()]\n",
    "df9_del=df1[df1.nondeleted_id.isnull()]\n",
    "df9_nondel=df1[df1.nondeleted_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "third-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames1=[df1_del,df2_del,df3_del,df4_del,df5_del,df6_del,df7_del,df8_del,df9_del]\n",
    "#frames2=[df1_nondel,df2_nondel,df3_nondel,df4_nondel,df5_nondel,df6_nondel,df7_nondel,df8_nondel,df9_nondel]\n",
    "frames1=[df1_del,df2_del]\n",
    "frames2=[df1_nondel,df2_nondel]\n",
    "df_del=pd.concat(frames1)\n",
    "df_nondel=pd.concat(frames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bacterial-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_del.to_csv('deleted_tweets_final.csv', index=False)\n",
    "df_nondel.to_csv('nondeleted_tweets_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "center-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_del['label']=0\n",
    "df_nondel['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "harmful-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58077, 2)\n",
      "(141923, 2)\n"
     ]
    }
   ],
   "source": [
    "df__del=df_del[['label','Text']]\n",
    "print(df__del.shape)\n",
    "df__nondel=df_nondel[['label','Text']]\n",
    "print(df__nondel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continuing-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower of text\n",
    "df__del['processed_text'] = df__del['Text'].str.lower()\n",
    "df__nondel['processed_text'] = df__nondel['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "juvenile-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing URL from text\n",
    "df__del['processed_text'] = df__del['processed_text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "df__nondel['processed_text'] = df__nondel['processed_text'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "renewable-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        rt @ncdcgov: we've updated national case defin...\n",
       "2        rt @brithume: nationwide fever-tracking data i...\n",
       "3        today things getting worse,my father had a hig...\n",
       "4        @ingrahamangle a friend of mine has covid19 an...\n",
       "5        rt @ariyoaristotle: coronavirus in nigeria?  l...\n",
       "                               ...                        \n",
       "99980    rt @mel_faith1: how many of you think you've a...\n",
       "99981    rt @brettkelman: we just had two big tennessee...\n",
       "99989    rt @unikgirl11: a doctor's visit will automati...\n",
       "99990    rt @candicemalcolm: btw i have developed some ...\n",
       "99998    rt @realdonaldtrfan: hey stormy… u up? you mus...\n",
       "Name: processed_text, Length: 58077, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__del['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interior-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rt from text\n",
    "df__del['processed_text'] = df__del['processed_text'].replace({'rt':''}, regex=True)\n",
    "df__nondel['processed_text'] = df__nondel['processed_text'].replace({'rt':''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "considered-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing emoji from text\n",
    "df__del['processed_text']=df__del['processed_text'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "df__nondel['processed_text']=df__nondel['processed_text'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"_\",\n",
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"–\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educational-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special characters from text\n",
    "for char in spec_chars:\n",
    "    df__del['processed_text'] = df__del['processed_text'].str.replace(char, ' ')\n",
    "    \n",
    "for char in spec_chars:\n",
    "    df__nondel['processed_text'] = df__nondel['processed_text'].str.replace(char, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seasonal-chapel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @ncdcgov: we've updated national case defin...</td>\n",
       "      <td>ncdcgov  we ve updated national case definit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @brithume: nationwide fever-tracking data i...</td>\n",
       "      <td>brithume  nationwide fever tracking data ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>today things getting worse,my father had a hig...</td>\n",
       "      <td>today things getting worse my father had a hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@ingrahamangle a friend of mine has covid19 an...</td>\n",
       "      <td>ingrahamangle a friend of mine has covid19 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @ariyoaristotle: coronavirus in nigeria?  l...</td>\n",
       "      <td>ariyoaristotle  coronavirus in nigeria   let...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               Text  \\\n",
       "1      0  rt @ncdcgov: we've updated national case defin...   \n",
       "2      0  rt @brithume: nationwide fever-tracking data i...   \n",
       "3      0  today things getting worse,my father had a hig...   \n",
       "4      0  @ingrahamangle a friend of mine has covid19 an...   \n",
       "5      0  rt @ariyoaristotle: coronavirus in nigeria?  l...   \n",
       "\n",
       "                                      processed_text  \n",
       "1    ncdcgov  we ve updated national case definit...  \n",
       "2    brithume  nationwide fever tracking data ind...  \n",
       "3  today things getting worse my father had a hig...  \n",
       "4   ingrahamangle a friend of mine has covid19 an...  \n",
       "5    ariyoaristotle  coronavirus in nigeria   let...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=pd.concat([df__del,df__nondel])\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "industrial-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "trying-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_final, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "upper-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('final_train_tweets_check.csv', index=False)\n",
    "df_test.to_csv('final_test_tweets_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "finnish-stick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41035</th>\n",
       "      <td>1</td>\n",
       "      <td>@martineholt9 @biggan4congress so my kid had a...</td>\n",
       "      <td>maineholt9  biggan4congress so my kid had all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58092</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @cbsnews: chris cuomo, who says he had hall...</td>\n",
       "      <td>cbsnews  chris cuomo  who says he had halluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66176</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @zfrmrza: 223/ if you or somebody you know ...</td>\n",
       "      <td>zfrmrza  223  if you or somebody you know ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @mancunianmedic: \"babylon covid bot?\" \"er y...</td>\n",
       "      <td>mancunianmedic   babylon covid bot    er yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87137</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @smccollection: please keep good self hygie...</td>\n",
       "      <td>smccollection  please keep good self hygiene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               Text  \\\n",
       "41035      1  @martineholt9 @biggan4congress so my kid had a...   \n",
       "58092      0  rt @cbsnews: chris cuomo, who says he had hall...   \n",
       "66176      1  rt @zfrmrza: 223/ if you or somebody you know ...   \n",
       "3614       1  rt @mancunianmedic: \"babylon covid bot?\" \"er y...   \n",
       "87137      1  rt @smccollection: please keep good self hygie...   \n",
       "\n",
       "                                          processed_text  \n",
       "41035   maineholt9  biggan4congress so my kid had all...  \n",
       "58092    cbsnews  chris cuomo  who says he had halluc...  \n",
       "66176    zfrmrza  223  if you or somebody you know ha...  \n",
       "3614     mancunianmedic   babylon covid bot    er yes...  \n",
       "87137    smccollection  please keep good self hygiene...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enhanced-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    99281\n",
       "0    40719\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "functioning-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install datasets==1.9.0 transformers==4.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unsigned-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "broke-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "assigned-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "light-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-343528053ae82419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\PROKO-WS\\.cache\\huggingface\\datasets\\csv\\default-343528053ae82419\\0.0.0\\9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\PROKO-WS\\.cache\\huggingface\\datasets\\csv\\default-343528053ae82419\\0.0.0\\9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': 'final_train_tweets_check.csv', 'test': 'final_test_tweets_check.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "injured-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'Text': \"rt @garethicke: just seen a post from a lady saying she's just been diagnosed with coronavirus, by her doctor.   over the phone. for callin…\",\n",
       " 'processed_text': '  garethicke  just seen a post from a lady saying she s just been diagnosed with coronavirus  by her doctor    over the phone  for callin'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "familiar-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(examples['processed_text'], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "designing-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2400198b00974265a8886f1b4852f8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93693b3c343242cfb3ff2729c954847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded = dataset['train'].map(encode, batched=True) # map applies the function \"encode\" to the specified \"dataset\"\n",
    "test_encoded = dataset['test'].map(encode, batched=True) # map applies the function \"encode\" to the specified \"dataset\"\n",
    "\n",
    "# we use only a subset of the loaded dataset\n",
    "train_dataset = train_encoded.shuffle(seed=42).select(range(100))\n",
    "eval_dataset = test_encoded.shuffle(seed=42).select(range(50))\n",
    "#train_dataset = train_encoded.shuffle(seed=42)\n",
    "#eval_dataset = test_encoded.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "billion-meter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "indian-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# the model must match the tokenizer used above and the number of labels must represent the classes for classification (binary, YES/NO -> 2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "indirect-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric # providing us with a diverse set of metrics for evaluation\n",
    "import numpy as np # a popular library for data manipulation and analysis (https://numpy.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "involved-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = load_metric(\"precision\")\n",
    "metric2 = load_metric(\"recall\")\n",
    "metric3 = load_metric(\"f1\")\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "circular-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metric1 = load_metric(\"precision\")\n",
    "    metric2 = load_metric(\"recall\")\n",
    "    metric3 = load_metric(\"f1\")\n",
    "    metric4 = load_metric(\"accuracy\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric1.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    recall = metric2.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    f1 = metric3.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "popular-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"deleted_tweets_trainer\",                  # output folder\n",
    "    num_train_epochs = 1,            # number of iterations over the whole dataset\n",
    "    logging_steps=100,               # number of steps to calculate and print out the current performance\n",
    "    evaluation_strategy='steps'      # used evaluate during the fine-tuning of our model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "institutional-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                      # our loaded pre-trained transformer-based model \"DistilBERT\"\n",
    "    args=training_args,               # our defined training arguments\n",
    "    train_dataset=train_dataset,      # the loaded IMDB training dataset from HuggingFace\n",
    "    eval_dataset=eval_dataset,        # the loaded IMDB evaluation dataset from HuggingFace\n",
    "    compute_metrics=compute_metrics   # our defined evaluation function \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mounted-recall",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 02:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=0.5865879058837891, metrics={'train_runtime': 174.2555, 'train_samples_per_second': 0.075, 'total_flos': 20568579072000.0, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': 4521, 'init_mem_cpu_peaked_delta': 13450, 'train_mem_cpu_alloc_delta': 275108, 'train_mem_cpu_peaked_delta': 147666})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "neither-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.60509192943573,\n",
       " 'eval_precision': 0.7857142857142857,\n",
       " 'eval_recall': 0.8461538461538461,\n",
       " 'eval_f1': 0.8148148148148148,\n",
       " 'eval_accuracy': 0.7,\n",
       " 'eval_runtime': 29.2871,\n",
       " 'eval_samples_per_second': 1.707,\n",
       " 'epoch': 1.0,\n",
       " 'eval_mem_cpu_alloc_delta': 178168,\n",
       " 'eval_mem_cpu_peaked_delta': 166508}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert_deleted_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-minute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
